/**
 * Servi√ßo Multi-Provedores de IA
 * Utiliza suas assinaturas existentes sem custos adicionais
 * Google Pro, ChatGPT Pro, Claude Pro, Manus Plus
 */

interface AIProvider {
  id: string;
  name: string;
  apiKey: string;
  endpoint: string;
  model: string;
  maxTokens: number;
  costPerToken: number;
  features: {
    textGeneration: boolean;
    codeGeneration: boolean;
    imageAnalysis: boolean;
    voiceProcessing: boolean;
    longContext: boolean;
  };
}

interface ProviderConfig {
  google: {
    apiKey: string;
    model: 'gemini-pro' | 'gemini-pro-vision';
  };
  openai: {
    apiKey: string;
    model: 'gpt-4' | 'gpt-4-turbo' | 'gpt-3.5-turbo';
  };
  anthropic: {
    apiKey: string;
    model: 'claude-3-opus' | 'claude-3-sonnet' | 'claude-3-haiku';
  };
  manus: {
    apiKey: string;
    endpoint: string;
  };
}

class MultiProviderAIService {
  private providers: Map<string, AIProvider> = new Map();
  private config: ProviderConfig;
  private currentProvider: string = 'google';
  private failoverOrder: string[] = ['google', 'openai', 'anthropic', 'manus'];
  private usageTracker: Map<string, { calls: number; tokens: number; date: string }> = new Map();

  constructor() {
    this.loadConfiguration();
    this.initializeProviders();
  }

  /**
   * Carrega configura√ß√£o das APIs das suas assinaturas
   */
  private loadConfiguration(): void {
    this.config = {
      google: {
        apiKey: localStorage.getItem('GOOGLE_PRO_API_KEY') || '',
        model: 'gemini-pro'
      },
      openai: {
        apiKey: localStorage.getItem('OPENAI_PRO_API_KEY') || '',
        model: 'gpt-4'
      },
      anthropic: {
        apiKey: localStorage.getItem('CLAUDE_PRO_API_KEY') || '',
        model: 'claude-3-sonnet'
      },
      manus: {
        apiKey: localStorage.getItem('MANUS_PLUS_API_KEY') || '',
        endpoint: localStorage.getItem('MANUS_PLUS_ENDPOINT') || ''
      }
    };
  }

  /**
   * Inicializa provedores com suas assinaturas
   */
  private initializeProviders(): void {
    // Google Gemini Pro (sua assinatura)
    if (this.config.google.apiKey) {
      this.providers.set('google', {
        id: 'google',
        name: 'Google Gemini Pro',
        apiKey: this.config.google.apiKey,
        endpoint: 'https://generativelanguage.googleapis.com/v1/models',
        model: this.config.google.model,
        maxTokens: 30720,
        costPerToken: 0, // J√° pago na sua assinatura!
        features: {
          textGeneration: true,
          codeGeneration: true,
          imageAnalysis: true,
          voiceProcessing: false,
          longContext: true
        }
      });
    }

    // OpenAI GPT Pro (sua assinatura)
    if (this.config.openai.apiKey) {
      this.providers.set('openai', {
        id: 'openai',
        name: 'OpenAI GPT Pro',
        apiKey: this.config.openai.apiKey,
        endpoint: 'https://api.openai.com/v1',
        model: this.config.openai.model,
        maxTokens: 8192,
        costPerToken: 0, // J√° pago na sua assinatura!
        features: {
          textGeneration: true,
          codeGeneration: true,
          imageAnalysis: true,
          voiceProcessing: true,
          longContext: false
        }
      });
    }

    // Claude Pro (sua assinatura)
    if (this.config.anthropic.apiKey) {
      this.providers.set('anthropic', {
        id: 'anthropic',
        name: 'Claude Pro',
        apiKey: this.config.anthropic.apiKey,
        endpoint: 'https://api.anthropic.com/v1',
        model: this.config.anthropic.model,
        maxTokens: 200000,
        costPerToken: 0, // J√° pago na sua assinatura!
        features: {
          textGeneration: true,
          codeGeneration: true,
          imageAnalysis: true,
          voiceProcessing: false,
          longContext: true
        }
      });
    }

    // Manus Plus (sua assinatura)
    if (this.config.manus.apiKey) {
      this.providers.set('manus', {
        id: 'manus',
        name: 'Manus Plus',
        apiKey: this.config.manus.apiKey,
        endpoint: this.config.manus.endpoint,
        model: 'manus-plus',
        maxTokens: 4096,
        costPerToken: 0, // J√° pago na sua assinatura!
        features: {
          textGeneration: true,
          codeGeneration: false,
          imageAnalysis: false,
          voiceProcessing: false,
          longContext: false
        }
      });
    }
  }

  /**
   * Gera texto usando o melhor provedor dispon√≠vel
   */
  async generateText(
    prompt: string,
    context: {
      type: 'assessment' | 'progress' | 'prescription' | 'report';
      systemPrompt?: string;
      maxTokens?: number;
      temperature?: number;
    }
  ): Promise<{
    content: string;
    provider: string;
    tokensUsed: number;
    cost: number;
  }> {
    const errors: string[] = [];

    for (const providerId of this.failoverOrder) {
      const provider = this.providers.get(providerId);
      if (!provider) continue;

      try {
        console.log(`ü§ñ Tentando ${provider.name}...`);
        const result = await this.callProvider(provider, prompt, context);
        
        this.trackUsage(providerId, result.tokensUsed);
        
        return {
          ...result,
          provider: provider.name,
          cost: 0 // Sempre R$ 0 pois voc√™ j√° paga as assinaturas!
        };
      } catch (error) {
        console.warn(`‚ùå ${provider.name} falhou:`, error);
        errors.push(`${provider.name}: ${error}`);
        continue;
      }
    }

    throw new Error(`Todos os provedores falharam: ${errors.join(', ')}`);
  }

  /**
   * Chama um provedor espec√≠fico
   */
  private async callProvider(
    provider: AIProvider,
    prompt: string,
    context: any
  ): Promise<{ content: string; tokensUsed: number }> {
    switch (provider.id) {
      case 'google':
        return await this.callGoogleGemini(provider, prompt, context);
      case 'openai':
        return await this.callOpenAI(provider, prompt, context);
      case 'anthropic':
        return await this.callClaude(provider, prompt, context);
      case 'manus':
        return await this.callManus(provider, prompt, context);
      default:
        throw new Error(`Provedor ${provider.id} n√£o implementado`);
    }
  }

  /**
   * Google Gemini Pro (sua assinatura)
   */
  private async callGoogleGemini(
    provider: AIProvider,
    prompt: string,
    context: any
  ): Promise<{ content: string; tokensUsed: number }> {
    const { GoogleGenerativeAI } = await import('@google/generative-ai');
    const genAI = new GoogleGenerativeAI(provider.apiKey);
    const model = genAI.getGenerativeModel({ 
      model: provider.model,
      systemInstruction: context.systemPrompt || this.getSystemPrompt(context.type)
    });

    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    return {
      content: text,
      tokensUsed: this.estimateTokens(prompt + text)
    };
  }

  /**
   * OpenAI GPT Pro (sua assinatura)
   */
  private async callOpenAI(
    provider: AIProvider,
    prompt: string,
    context: any
  ): Promise<{ content: string; tokensUsed: number }> {
    const response = await fetch(`${provider.endpoint}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${provider.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: provider.model,
        messages: [
          {
            role: 'system',
            content: context.systemPrompt || this.getSystemPrompt(context.type)
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: context.maxTokens || 2000,
        temperature: context.temperature || 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    
    return {
      content: data.choices[0].message.content,
      tokensUsed: data.usage.total_tokens
    };
  }

  /**
   * Claude Pro (sua assinatura)
   */
  private async callClaude(
    provider: AIProvider,
    prompt: string,
    context: any
  ): Promise<{ content: string; tokensUsed: number }> {
    const response = await fetch(`${provider.endpoint}/messages`, {
      method: 'POST',
      headers: {
        'x-api-key': provider.apiKey,
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01'
      },
      body: JSON.stringify({
        model: provider.model,
        max_tokens: context.maxTokens || 2000,
        system: context.systemPrompt || this.getSystemPrompt(context.type),
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
        temperature: context.temperature || 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`Claude API error: ${response.status}`);
    }

    const data = await response.json();
    
    return {
      content: data.content[0].text,
      tokensUsed: data.usage.input_tokens + data.usage.output_tokens
    };
  }

  /**
   * Manus Plus (sua assinatura)
   */
  private async callManus(
    provider: AIProvider,
    prompt: string,
    context: any
  ): Promise<{ content: string; tokensUsed: number }> {
    // Implementa√ß√£o espec√≠fica para Manus Plus
    // Ajuste conforme a API do Manus
    const response = await fetch(provider.endpoint, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${provider.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        prompt: prompt,
        system: context.systemPrompt || this.getSystemPrompt(context.type),
        max_tokens: context.maxTokens || 2000,
        temperature: context.temperature || 0.7,
      }),
    });

    if (!response.ok) {
      throw new Error(`Manus API error: ${response.status}`);
    }

    const data = await response.json();
    
    return {
      content: data.text || data.content || data.response,
      tokensUsed: this.estimateTokens(prompt + (data.text || data.content || data.response))
    };
  }

  /**
   * Prompts do sistema por tipo de documento
   */
  private getSystemPrompt(type: string): string {
    const prompts = {
      assessment: 'Voc√™ √© um fisioterapeuta experiente criando uma avalia√ß√£o cl√≠nica detalhada. Use linguagem t√©cnica precisa e estruture o conte√∫do de forma profissional.',
      progress: 'Voc√™ √© um fisioterapeuta documentando a evolu√ß√£o de um paciente. Foque na compara√ß√£o entre estados anteriores e atuais, destacando melhorias e ajustes necess√°rios.',
      prescription: 'Voc√™ √© um fisioterapeuta prescrevendo exerc√≠cios terap√™uticos. Forne√ßa instru√ß√µes claras, progress√µes adequadas e cuidados espec√≠ficos.',
      report: 'Voc√™ √© um fisioterapeuta elaborando um relat√≥rio oficial. Use formata√ß√£o adequada para documenta√ß√£o m√©dica formal e linguagem t√©cnica apropriada.'
    };
    
    return prompts[type as keyof typeof prompts] || prompts.assessment;
  }

  /**
   * Estimativa simples de tokens
   */
  private estimateTokens(text: string): number {
    return Math.ceil(text.length / 4); // Aproxima√ß√£o: 1 token ‚âà 4 caracteres
  }

  /**
   * Rastreia uso por provedor
   */
  private trackUsage(providerId: string, tokens: number): void {
    const today = new Date().toISOString().split('T')[0];
    const key = `${providerId}_${today}`;
    
    const current = this.usageTracker.get(key) || { calls: 0, tokens: 0, date: today };
    current.calls++;
    current.tokens += tokens;
    
    this.usageTracker.set(key, current);
    
    // Salva no localStorage
    try {
      localStorage.setItem('aiProviderUsage', JSON.stringify(Array.from(this.usageTracker.entries())));
    } catch (error) {
      console.warn('Erro ao salvar uso dos provedores:', error);
    }
  }

  /**
   * M√©todos espec√≠ficos para cada tipo de documento
   */
  async generateEvolutionReport(patient: any, sessions: any[]): Promise<string> {
    const prompt = `
Gere um relat√≥rio de evolu√ß√£o fisioterap√™utica para:

**Paciente:** ${patient.name}
**Hist√≥rico:** ${patient.medicalHistory}

**Sess√µes:**
${sessions.map(s => `- ${s.date}: ${s.notes || 'Sess√£o realizada'} (Dor: ${s.painLevel}/10)`).join('\n')}

Estruture o relat√≥rio com: Resumo do caso, Evolu√ß√£o observada, M√©tricas objetivas, Recomenda√ß√µes.
    `;

    const result = await this.generateText(prompt, { type: 'progress' });
    return result.content;
  }

  async generateInsuranceReport(patient: any, type: 'convenio' | 'pericia' | 'alta'): Promise<string> {
    const prompts = {
      convenio: 'Gere um relat√≥rio m√©dico para conv√™nio justificando a necessidade de continuidade do tratamento fisioterap√™utico.',
      pericia: 'Gere um relat√≥rio pericial fisioterap√™utico objetivo avaliando capacidade funcional e limita√ß√µes.',
      alta: 'Gere uma carta de alta fisioterap√™utica documentando resultados obtidos e orienta√ß√µes de manuten√ß√£o.'
    };

    const prompt = `
${prompts[type]}

**Paciente:** ${patient.name}
**Hist√≥rico Cl√≠nico:** ${patient.medicalHistory}

Use formata√ß√£o oficial e linguagem t√©cnica apropriada para documenta√ß√£o m√©dica.
    `;

    const result = await this.generateText(prompt, { type: 'report' });
    return result.content;
  }

  async generateExercisePrescription(prescriptions: any[], exercises: any[], patient: any): Promise<string> {
    const exerciseDetails = prescriptions.map(p => {
      const exercise = exercises.find(e => e.id === p.exerciseId);
      return `${exercise?.name || 'Exerc√≠cio'}: ${p.sets} s√©ries, ${p.reps} repeti√ß√µes, ${p.frequency}`;
    }).join('\n');

    const prompt = `
Gere um receitu√°rio de exerc√≠cios fisioterap√™uticos para:

**Paciente:** ${patient.name}
**Condi√ß√£o:** ${patient.medicalHistory}

**Exerc√≠cios Prescritos:**
${exerciseDetails}

Inclua: instru√ß√µes detalhadas, cuidados, progress√µes e orienta√ß√µes gerais.
    `;

    const result = await this.generateText(prompt, { type: 'prescription' });
    return result.content;
  }

  async processVoiceToText(text: string, contextType: string): Promise<string> {
    const prompt = `
Melhore e estruture este texto ditado por voz no contexto de ${contextType} fisioterap√™utico:

"${text}"

Corrija erros de transcri√ß√£o, melhore a estrutura e padronize terminologia m√©dica.
    `;

    const result = await this.generateText(prompt, { type: contextType as any });
    return result.content;
  }

  async correctMedicalTerminology(text: string): Promise<string> {
    const prompt = `
Corrija a terminologia m√©dica e fisioterap√™utica neste texto:

"${text}"

Mantenha o conte√∫do original, apenas corrigindo termos t√©cnicos e padronizando a linguagem cl√≠nica.
    `;

    const result = await this.generateText(prompt, { type: 'assessment' });
    return result.content;
  }

  async translateToPatientLanguage(text: string): Promise<string> {
    const prompt = `
Traduza este texto t√©cnico para linguagem acess√≠vel ao paciente:

"${text}"

Use termos simples, explica√ß√µes claras e evite jarg√µes m√©dicos mantendo a precis√£o das informa√ß√µes.
    `;

    const result = await this.generateText(prompt, { type: 'assessment' });
    return result.content;
  }

  /**
   * Dashboard de uso
   */
  getUsageDashboard(): {
    providers: { name: string; available: boolean; todayUsage: number }[];
    totalCost: number;
    bestProvider: string;
    recommendations: string[];
  } {
    const today = new Date().toISOString().split('T')[0];
    const providers = Array.from(this.providers.values()).map(provider => {
      const usage = this.usageTracker.get(`${provider.id}_${today}`);
      return {
        name: provider.name,
        available: !!provider.apiKey,
        todayUsage: usage?.calls || 0
      };
    });

    return {
      providers,
      totalCost: 0, // Sempre R$ 0,00 pois voc√™ j√° paga as assinaturas!
      bestProvider: this.getBestProvider(),
      recommendations: this.getRecommendations()
    };
  }

  private getBestProvider(): string {
    // L√≥gica para determinar o melhor provedor baseado em performance
    const available = Array.from(this.providers.values()).filter(p => p.apiKey);
    if (available.length === 0) return 'Nenhum configurado';
    
    // Prioriza Claude para textos longos, GPT para versatilidade, Gemini para an√°lise
    if (this.providers.has('anthropic')) return 'Claude Pro';
    if (this.providers.has('openai')) return 'GPT Pro';
    if (this.providers.has('google')) return 'Gemini Pro';
    return available[0].name;
  }

  private getRecommendations(): string[] {
    const recommendations: string[] = [];
    
    if (!this.providers.has('google')) {
      recommendations.push('Configure sua API do Google Gemini Pro para an√°lise de documentos');
    }
    if (!this.providers.has('openai')) {
      recommendations.push('Adicione sua API do ChatGPT Pro para versatilidade m√°xima');
    }
    if (!this.providers.has('anthropic')) {
      recommendations.push('Configure Claude Pro para textos longos e an√°lise detalhada');
    }
    
    if (recommendations.length === 0) {
      recommendations.push('Todas as suas assinaturas est√£o configuradas! Custo total: R$ 0,00 üíö');
    }
    
    return recommendations;
  }

  /**
   * Configura√ß√£o das APIs
   */
  setProviderConfig(providerId: keyof ProviderConfig, config: any): void {
    switch (providerId) {
      case 'google':
        localStorage.setItem('GOOGLE_PRO_API_KEY', config.apiKey);
        this.config.google = config;
        break;
      case 'openai':
        localStorage.setItem('OPENAI_PRO_API_KEY', config.apiKey);
        this.config.openai = config;
        break;
      case 'anthropic':
        localStorage.setItem('CLAUDE_PRO_API_KEY', config.apiKey);
        this.config.anthropic = config;
        break;
      case 'manus':
        localStorage.setItem('MANUS_PLUS_API_KEY', config.apiKey);
        localStorage.setItem('MANUS_PLUS_ENDPOINT', config.endpoint);
        this.config.manus = config;
        break;
    }
    
    this.initializeProviders(); // Re-inicializa com nova config
  }

  getConfiguredProviders(): string[] {
    return Array.from(this.providers.keys());
  }
}

// Inst√¢ncia singleton
export const multiAI = new MultiProviderAIService();

// Fun√ß√£o de conveni√™ncia
export async function generateWithYourSubscriptions(
  prompt: string,
  type: 'assessment' | 'progress' | 'prescription' | 'report'
): Promise<string> {
  const result = await multiAI.generateText(prompt, { type });
  return result.content;
}